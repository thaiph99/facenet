arguments: src/align/align_dataset_mtcnn.py dataset/datatrain datasets/dataalign --image_size 182 --margin 44
--------------------
tensorflow version: 2.3.0
--------------------
git hash: b'af0ec925eb7d819860d136cb3cb0f4f201afd616'
--------------------
b'diff --git a/src/align/align_dataset_mtcnn.py b/src/align/align_dataset_mtcnn.py\nindex 7d5e735..ca04e59 100644\n--- a/src/align/align_dataset_mtcnn.py\n+++ b/src/align/align_dataset_mtcnn.py\n@@ -29,39 +29,40 @@ from scipy import misc\n import sys\n import os\n import argparse\n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n import facenet\n-import align.detect_face\n+import detect_face\n import random\n from time import sleep\n \n+\n def main(args):\n     sleep(random.random())\n     output_dir = os.path.expanduser(args.output_dir)\n     if not os.path.exists(output_dir):\n         os.makedirs(output_dir)\n     # Store some git revision info in a text file in the log directory\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\n+    src_path, _ = os.path.split(os.path.realpath(__file__))\n     facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n     dataset = facenet.get_dataset(args.input_dir)\n-    \n+\n     print(\'Creating networks and loading parameters\')\n-    \n+\n     with tf.Graph().as_default():\n         gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n         sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n         with sess.as_default():\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n-    minsize = 20 # minimum size of face\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n-    factor = 0.709 # scale factor\n+            pnet, rnet, onet = detect_face.create_mtcnn(sess, None)\n+\n+    minsize = 20  # minimum size of face\n+    threshold = [0.6, 0.7, 0.7]  # three steps\'s threshold\n+    factor = 0.709  # scale factor\n \n     # Add a random key to the filename to allow alignment using multiple processes\n     random_key = np.random.randint(0, high=99999)\n     bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n+\n     with open(bounding_boxes_filename, "w") as text_file:\n         nrof_images_total = 0\n         nrof_successfully_aligned = 0\n@@ -76,7 +77,7 @@ def main(args):\n             for image_path in cls.image_paths:\n                 nrof_images_total += 1\n                 filename = os.path.splitext(os.path.split(image_path)[1])[0]\n-                output_filename = os.path.join(output_class_dir, filename+\'.png\')\n+                output_filename = os.path.join(output_class_dir, filename + \'.png\')\n                 print(image_path)\n                 if not os.path.exists(output_filename):\n                     try:\n@@ -85,42 +86,45 @@ def main(args):\n                         errorMessage = \'{}: {}\'.format(image_path, e)\n                         print(errorMessage)\n                     else:\n-                        if img.ndim<2:\n+                        if img.ndim < 2:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n                             continue\n                         if img.ndim == 2:\n                             img = facenet.to_rgb(img)\n-                        img = img[:,:,0:3]\n-    \n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n+                        img = img[:, :, 0:3]\n+\n+                        bounding_boxes, _ = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold,\n+                                                                          factor)\n                         nrof_faces = bounding_boxes.shape[0]\n-                        if nrof_faces>0:\n-                            det = bounding_boxes[:,0:4]\n+                        if nrof_faces > 0:\n+                            det = bounding_boxes[:, 0:4]\n                             det_arr = []\n                             img_size = np.asarray(img.shape)[0:2]\n-                            if nrof_faces>1:\n+                            if nrof_faces > 1:\n                                 if args.detect_multiple_faces:\n                                     for i in range(nrof_faces):\n                                         det_arr.append(np.squeeze(det[i]))\n                                 else:\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n+                                    bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\n                                     img_center = img_size / 2\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                    det_arr.append(det[index,:])\n+                                    offsets = np.vstack([(det[:, 0] + det[:, 2]) / 2 - img_center[1],\n+                                                         (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\n+                                    offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n+                                    index = np.argmax(\n+                                        bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\n+                                    det_arr.append(det[index, :])\n                             else:\n                                 det_arr.append(np.squeeze(det))\n \n                             for i, det in enumerate(det_arr):\n                                 det = np.squeeze(det)\n                                 bb = np.zeros(4, dtype=np.int32)\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n+                                bb[0] = np.maximum(det[0] - args.margin / 2, 0)\n+                                bb[1] = np.maximum(det[1] - args.margin / 2, 0)\n+                                bb[2] = np.minimum(det[2] + args.margin / 2, img_size[1])\n+                                bb[3] = np.minimum(det[3] + args.margin / 2, img_size[0])\n+                                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]\n                                 scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n@@ -133,27 +137,29 @@ def main(args):\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\n                             text_file.write(\'%s\\n\' % (output_filename))\n-                            \n+\n     print(\'Total number of images: %d\' % nrof_images_total)\n     print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n+\n \n def parse_arguments(argv):\n     parser = argparse.ArgumentParser()\n-    \n+\n     parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n     parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n     parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n+                        help=\'Image size (height, width) in pixels.\', default=182)\n     parser.add_argument(\'--margin\', type=int,\n-        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n-        help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n+                        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n+    parser.add_argument(\'--random_order\',\n+                        help=\'Shuffles the order of images to enable alignment using multiple processes.\',\n+                        action=\'store_true\')\n     parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n+                        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n     parser.add_argument(\'--detect_multiple_faces\', type=bool,\n                         help=\'Detect and align multiple faces per image.\', default=False)\n     return parser.parse_args(argv)\n \n+\n if __name__ == \'__main__\':\n     main(parse_arguments(sys.argv[1:]))\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 7f98ca7..c409be7 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -29,11 +29,12 @@ from __future__ import print_function\n from six import string_types, iteritems\n \n import numpy as np\n-import tensorflow as tf\n-#from math import floor\n+import tensorflow.compat.v1 as tf\n+# from math import floor\n import cv2\n import os\n \n+\n def layer(op):\n     """Decorator for composable network layers."""\n \n@@ -58,6 +59,7 @@ def layer(op):\n \n     return layer_decorated\n \n+\n class Network(object):\n \n     def __init__(self, inputs, trainable=True):\n@@ -82,7 +84,7 @@ class Network(object):\n         session: The current TensorFlow session\n         ignore_missing: If true, serialized weights for missing layers are ignored.\n         """\n-        data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        data_dict = np.load(data_path, encoding=\'latin1\').item()  # pylint: disable=no-member\n \n         for op_name in data_dict:\n             with tf.variable_scope(op_name, reuse=True):\n@@ -198,103 +200,109 @@ class Network(object):\n             fc = op(feed_in, weights, biases, name=name)\n             return fc\n \n-\n     """\n     Multi dimensional softmax,\n     refer to https://github.com/tensorflow/tensorflow/issues/210\n     compute softmax along the dimension of target\n     the native softmax only supports batch_size x dimension\n     """\n+\n     @layer\n     def softmax(self, target, axis, name=None):\n         max_axis = tf.reduce_max(target, axis, keepdims=True)\n-        target_exp = tf.exp(target-max_axis)\n+        target_exp = tf.exp(target - max_axis)\n         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n         softmax = tf.div(target_exp, normalize, name)\n         return softmax\n-    \n+\n+\n class PNet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'PReLU1\')\n-             .max_pool(2, 2, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 16, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'PReLU2\')\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'PReLU3\')\n-             .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n-             .softmax(3,name=\'prob1\'))\n-\n-        (self.feed(\'PReLU3\') #pylint: disable=no-value-for-parameter\n-             .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n-        \n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'PReLU1\')\n+         .max_pool(2, 2, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 16, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'PReLU2\')\n+         .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'PReLU3\')\n+         .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n+         .softmax(3, name=\'prob1\'))\n+\n+        (self.feed(\'PReLU3\')  # pylint: disable=no-value-for-parameter\n+         .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n+\n+\n class RNet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 48, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(2, 2, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .fc(128, relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(2, relu=False, name=\'conv5-1\')\n-             .softmax(1,name=\'prob1\'))\n-\n-        (self.feed(\'prelu4\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv5-2\'))\n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'prelu1\')\n+         .max_pool(3, 3, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 48, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'prelu2\')\n+         .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n+         .conv(2, 2, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'prelu3\')\n+         .fc(128, relu=False, name=\'conv4\')\n+         .prelu(name=\'prelu4\')\n+         .fc(2, relu=False, name=\'conv5-1\')\n+         .softmax(1, name=\'prob1\'))\n+\n+        (self.feed(\'prelu4\')  # pylint: disable=no-value-for-parameter\n+         .fc(4, relu=False, name=\'conv5-2\'))\n+\n \n class ONet(Network):\n     def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .max_pool(2, 2, 2, 2, name=\'pool3\')\n-             .conv(2, 2, 128, 1, 1, padding=\'VALID\', relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(256, relu=False, name=\'conv5\')\n-             .prelu(name=\'prelu5\')\n-             .fc(2, relu=False, name=\'conv6-1\')\n-             .softmax(1, name=\'prob1\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv6-2\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(10, relu=False, name=\'conv6-3\'))\n+        (self.feed(\'data\')  # pylint: disable=no-value-for-parameter, no-member\n+         .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n+         .prelu(name=\'prelu1\')\n+         .max_pool(3, 3, 2, 2, name=\'pool1\')\n+         .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n+         .prelu(name=\'prelu2\')\n+         .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n+         .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n+         .prelu(name=\'prelu3\')\n+         .max_pool(2, 2, 2, 2, name=\'pool3\')\n+         .conv(2, 2, 128, 1, 1, padding=\'VALID\', relu=False, name=\'conv4\')\n+         .prelu(name=\'prelu4\')\n+         .fc(256, relu=False, name=\'conv5\')\n+         .prelu(name=\'prelu5\')\n+         .fc(2, relu=False, name=\'conv6-1\')\n+         .softmax(1, name=\'prob1\'))\n+\n+        (self.feed(\'prelu5\')  # pylint: disable=no-value-for-parameter\n+         .fc(4, relu=False, name=\'conv6-2\'))\n+\n+        (self.feed(\'prelu5\')  # pylint: disable=no-value-for-parameter\n+         .fc(10, relu=False, name=\'conv6-3\'))\n+\n \n def create_mtcnn(sess, model_path):\n     if not model_path:\n-        model_path,_ = os.path.split(os.path.realpath(__file__))\n+        model_path, _ = os.path.split(os.path.realpath(__file__))\n \n     with tf.variable_scope(\'pnet\'):\n-        data = tf.placeholder(tf.float32, (None,None,None,3), \'input\')\n-        pnet = PNet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, None, None, 3), \'input\')\n+        pnet = PNet({\'data\': data})\n         pnet.load(os.path.join(model_path, \'det1.npy\'), sess)\n     with tf.variable_scope(\'rnet\'):\n-        data = tf.placeholder(tf.float32, (None,24,24,3), \'input\')\n-        rnet = RNet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, 24, 24, 3), \'input\')\n+        rnet = RNet({\'data\': data})\n         rnet.load(os.path.join(model_path, \'det2.npy\'), sess)\n     with tf.variable_scope(\'onet\'):\n-        data = tf.placeholder(tf.float32, (None,48,48,3), \'input\')\n-        onet = ONet({\'data\':data})\n+        data = tf.placeholder(tf.float32, (None, 48, 48, 3), \'input\')\n+        onet = ONet({\'data\': data})\n         onet.load(os.path.join(model_path, \'det3.npy\'), sess)\n-        \n-    pnet_fun = lambda img : sess.run((\'pnet/conv4-2/BiasAdd:0\', \'pnet/prob1:0\'), feed_dict={\'pnet/input:0\':img})\n-    rnet_fun = lambda img : sess.run((\'rnet/conv5-2/conv5-2:0\', \'rnet/prob1:0\'), feed_dict={\'rnet/input:0\':img})\n-    onet_fun = lambda img : sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'), feed_dict={\'onet/input:0\':img})\n+\n+    pnet_fun = lambda img: sess.run((\'pnet/conv4-2/BiasAdd:0\', \'pnet/prob1:0\'), feed_dict={\'pnet/input:0\': img})\n+    rnet_fun = lambda img: sess.run((\'rnet/conv5-2/conv5-2:0\', \'rnet/prob1:0\'), feed_dict={\'rnet/input:0\': img})\n+    onet_fun = lambda img: sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'),\n+                                    feed_dict={\'onet/input:0\': img})\n     return pnet_fun, rnet_fun, onet_fun\n \n+\n def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n     """Detects faces in an image, and returns bounding boxes and points for them.\n     img: input image\n@@ -303,118 +311,118 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n     threshold: threshold=[th1, th2, th3], th1-3 are three steps\'s threshold\n     factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n     """\n-    factor_count=0\n-    total_boxes=np.empty((0,9))\n-    points=np.empty(0)\n-    h=img.shape[0]\n-    w=img.shape[1]\n-    minl=np.amin([h, w])\n-    m=12.0/minsize\n-    minl=minl*m\n+    factor_count = 0\n+    total_boxes = np.empty((0, 9))\n+    points = np.empty(0)\n+    h = img.shape[0]\n+    w = img.shape[1]\n+    minl = np.amin([h, w])\n+    m = 12.0 / minsize\n+    minl = minl * m\n     # create scale pyramid\n-    scales=[]\n-    while minl>=12:\n-        scales += [m*np.power(factor, factor_count)]\n-        minl = minl*factor\n+    scales = []\n+    while minl >= 12:\n+        scales += [m * np.power(factor, factor_count)]\n+        minl = minl * factor\n         factor_count += 1\n \n     # first stage\n     for scale in scales:\n-        hs=int(np.ceil(h*scale))\n-        ws=int(np.ceil(w*scale))\n+        hs = int(np.ceil(h * scale))\n+        ws = int(np.ceil(w * scale))\n         im_data = imresample(img, (hs, ws))\n-        im_data = (im_data-127.5)*0.0078125\n+        im_data = (im_data - 127.5) * 0.0078125\n         img_x = np.expand_dims(im_data, 0)\n-        img_y = np.transpose(img_x, (0,2,1,3))\n+        img_y = np.transpose(img_x, (0, 2, 1, 3))\n         out = pnet(img_y)\n-        out0 = np.transpose(out[0], (0,2,1,3))\n-        out1 = np.transpose(out[1], (0,2,1,3))\n-        \n-        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n-        \n+        out0 = np.transpose(out[0], (0, 2, 1, 3))\n+        out1 = np.transpose(out[1], (0, 2, 1, 3))\n+\n+        boxes, _ = generateBoundingBox(out1[0, :, :, 1].copy(), out0[0, :, :, :].copy(), scale, threshold[0])\n+\n         # inter-scale nms\n         pick = nms(boxes.copy(), 0.5, \'Union\')\n-        if boxes.size>0 and pick.size>0:\n-            boxes = boxes[pick,:]\n+        if boxes.size > 0 and pick.size > 0:\n+            boxes = boxes[pick, :]\n             total_boxes = np.append(total_boxes, boxes, axis=0)\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         pick = nms(total_boxes.copy(), 0.7, \'Union\')\n-        total_boxes = total_boxes[pick,:]\n-        regw = total_boxes[:,2]-total_boxes[:,0]\n-        regh = total_boxes[:,3]-total_boxes[:,1]\n-        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n-        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n-        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n-        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n-        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n+        total_boxes = total_boxes[pick, :]\n+        regw = total_boxes[:, 2] - total_boxes[:, 0]\n+        regh = total_boxes[:, 3] - total_boxes[:, 1]\n+        qq1 = total_boxes[:, 0] + total_boxes[:, 5] * regw\n+        qq2 = total_boxes[:, 1] + total_boxes[:, 6] * regh\n+        qq3 = total_boxes[:, 2] + total_boxes[:, 7] * regw\n+        qq4 = total_boxes[:, 3] + total_boxes[:, 8] * regh\n+        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:, 4]]))\n         total_boxes = rerec(total_boxes.copy())\n-        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n+        total_boxes[:, 0:4] = np.fix(total_boxes[:, 0:4]).astype(np.int32)\n         dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         # second stage\n-        tempimg = np.zeros((24,24,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n+        tempimg = np.zeros((24, 24, 3, numbox))\n+        for k in range(0, numbox):\n+            tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n+            tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = img[y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n+                tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n             else:\n                 return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n+        tempimg = (tempimg - 127.5) * 0.0078125\n+        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n         out = rnet(tempimg1)\n         out0 = np.transpose(out[0])\n         out1 = np.transpose(out[1])\n-        score = out1[1,:]\n-        ipass = np.where(score>threshold[1])\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-        if total_boxes.shape[0]>0:\n+        score = out1[1, :]\n+        ipass = np.where(score > threshold[1])\n+        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n+        mv = out0[:, ipass[0]]\n+        if total_boxes.shape[0] > 0:\n             pick = nms(total_boxes, 0.7, \'Union\')\n-            total_boxes = total_boxes[pick,:]\n-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n+            total_boxes = total_boxes[pick, :]\n+            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:, pick]))\n             total_boxes = rerec(total_boxes.copy())\n \n     numbox = total_boxes.shape[0]\n-    if numbox>0:\n+    if numbox > 0:\n         # third stage\n         total_boxes = np.fix(total_boxes).astype(np.int32)\n         dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n-        tempimg = np.zeros((48,48,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n+        tempimg = np.zeros((48, 48, 3, numbox))\n+        for k in range(0, numbox):\n+            tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n+            tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = img[y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n+                tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n             else:\n                 return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n+        tempimg = (tempimg - 127.5) * 0.0078125\n+        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n         out = onet(tempimg1)\n         out0 = np.transpose(out[0])\n         out1 = np.transpose(out[1])\n         out2 = np.transpose(out[2])\n-        score = out2[1,:]\n+        score = out2[1, :]\n         points = out1\n-        ipass = np.where(score>threshold[2])\n-        points = points[:,ipass[0]]\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-\n-        w = total_boxes[:,2]-total_boxes[:,0]+1\n-        h = total_boxes[:,3]-total_boxes[:,1]+1\n-        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n-        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n-        if total_boxes.shape[0]>0:\n+        ipass = np.where(score > threshold[2])\n+        points = points[:, ipass[0]]\n+        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n+        mv = out0[:, ipass[0]]\n+\n+        w = total_boxes[:, 2] - total_boxes[:, 0] + 1\n+        h = total_boxes[:, 3] - total_boxes[:, 1] + 1\n+        points[0:5, :] = np.tile(w, (5, 1)) * points[0:5, :] + np.tile(total_boxes[:, 0], (5, 1)) - 1\n+        points[5:10, :] = np.tile(h, (5, 1)) * points[5:10, :] + np.tile(total_boxes[:, 1], (5, 1)) - 1\n+        if total_boxes.shape[0] > 0:\n             total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n             pick = nms(total_boxes.copy(), 0.7, \'Min\')\n-            total_boxes = total_boxes[pick,:]\n-            points = points[:,pick]\n-                \n+            total_boxes = total_boxes[pick, :]\n+            points = points[:, pick]\n+\n     return total_boxes, points\n \n \n@@ -643,60 +651,62 @@ def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, thre\n \n \n # function [boundingbox] = bbreg(boundingbox,reg)\n-def bbreg(boundingbox,reg):\n+def bbreg(boundingbox, reg):\n     """Calibrate bounding boxes"""\n-    if reg.shape[1]==1:\n+    if reg.shape[1] == 1:\n         reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n \n-    w = boundingbox[:,2]-boundingbox[:,0]+1\n-    h = boundingbox[:,3]-boundingbox[:,1]+1\n-    b1 = boundingbox[:,0]+reg[:,0]*w\n-    b2 = boundingbox[:,1]+reg[:,1]*h\n-    b3 = boundingbox[:,2]+reg[:,2]*w\n-    b4 = boundingbox[:,3]+reg[:,3]*h\n-    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n+    w = boundingbox[:, 2] - boundingbox[:, 0] + 1\n+    h = boundingbox[:, 3] - boundingbox[:, 1] + 1\n+    b1 = boundingbox[:, 0] + reg[:, 0] * w\n+    b2 = boundingbox[:, 1] + reg[:, 1] * h\n+    b3 = boundingbox[:, 2] + reg[:, 2] * w\n+    b4 = boundingbox[:, 3] + reg[:, 3] * h\n+    boundingbox[:, 0:4] = np.transpose(np.vstack([b1, b2, b3, b4]))\n     return boundingbox\n- \n+\n+\n def generateBoundingBox(imap, reg, scale, t):\n     """Use heatmap to generate bounding boxes"""\n-    stride=2\n-    cellsize=12\n+    stride = 2\n+    cellsize = 12\n \n     imap = np.transpose(imap)\n-    dx1 = np.transpose(reg[:,:,0])\n-    dy1 = np.transpose(reg[:,:,1])\n-    dx2 = np.transpose(reg[:,:,2])\n-    dy2 = np.transpose(reg[:,:,3])\n+    dx1 = np.transpose(reg[:, :, 0])\n+    dy1 = np.transpose(reg[:, :, 1])\n+    dx2 = np.transpose(reg[:, :, 2])\n+    dy2 = np.transpose(reg[:, :, 3])\n     y, x = np.where(imap >= t)\n-    if y.shape[0]==1:\n+    if y.shape[0] == 1:\n         dx1 = np.flipud(dx1)\n         dy1 = np.flipud(dy1)\n         dx2 = np.flipud(dx2)\n         dy2 = np.flipud(dy2)\n-    score = imap[(y,x)]\n-    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n-    if reg.size==0:\n-        reg = np.empty((0,3))\n-    bb = np.transpose(np.vstack([y,x]))\n-    q1 = np.fix((stride*bb+1)/scale)\n-    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n-    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n+    score = imap[(y, x)]\n+    reg = np.transpose(np.vstack([dx1[(y, x)], dy1[(y, x)], dx2[(y, x)], dy2[(y, x)]]))\n+    if reg.size == 0:\n+        reg = np.empty((0, 3))\n+    bb = np.transpose(np.vstack([y, x]))\n+    q1 = np.fix((stride * bb + 1) / scale)\n+    q2 = np.fix((stride * bb + cellsize - 1 + 1) / scale)\n+    boundingbox = np.hstack([q1, q2, np.expand_dims(score, 1), reg])\n     return boundingbox, reg\n- \n+\n+\n # function pick = nms(boxes,threshold,type)\n def nms(boxes, threshold, method):\n-    if boxes.size==0:\n-        return np.empty((0,3))\n-    x1 = boxes[:,0]\n-    y1 = boxes[:,1]\n-    x2 = boxes[:,2]\n-    y2 = boxes[:,3]\n-    s = boxes[:,4]\n-    area = (x2-x1+1) * (y2-y1+1)\n+    if boxes.size == 0:\n+        return np.empty((0, 3))\n+    x1 = boxes[:, 0]\n+    y1 = boxes[:, 1]\n+    x2 = boxes[:, 2]\n+    y2 = boxes[:, 3]\n+    s = boxes[:, 4]\n+    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n     I = np.argsort(s)\n     pick = np.zeros_like(s, dtype=np.int16)\n     counter = 0\n-    while I.size>0:\n+    while I.size > 0:\n         i = I[-1]\n         pick[counter] = i\n         counter += 1\n@@ -705,22 +715,23 @@ def nms(boxes, threshold, method):\n         yy1 = np.maximum(y1[i], y1[idx])\n         xx2 = np.minimum(x2[i], x2[idx])\n         yy2 = np.minimum(y2[i], y2[idx])\n-        w = np.maximum(0.0, xx2-xx1+1)\n-        h = np.maximum(0.0, yy2-yy1+1)\n+        w = np.maximum(0.0, xx2 - xx1 + 1)\n+        h = np.maximum(0.0, yy2 - yy1 + 1)\n         inter = w * h\n         if method is \'Min\':\n             o = inter / np.minimum(area[i], area[idx])\n         else:\n             o = inter / (area[i] + area[idx] - inter)\n-        I = I[np.where(o<=threshold)]\n+        I = I[np.where(o <= threshold)]\n     pick = pick[0:counter]\n     return pick\n \n+\n # function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n def pad(total_boxes, w, h):\n     """Compute the padding coordinates (pad the bounding boxes to square)"""\n-    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n-    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n+    tmpw = (total_boxes[:, 2] - total_boxes[:, 0] + 1).astype(np.int32)\n+    tmph = (total_boxes[:, 3] - total_boxes[:, 1] + 1).astype(np.int32)\n     numbox = total_boxes.shape[0]\n \n     dx = np.ones((numbox), dtype=np.int32)\n@@ -728,42 +739,44 @@ def pad(total_boxes, w, h):\n     edx = tmpw.copy().astype(np.int32)\n     edy = tmph.copy().astype(np.int32)\n \n-    x = total_boxes[:,0].copy().astype(np.int32)\n-    y = total_boxes[:,1].copy().astype(np.int32)\n-    ex = total_boxes[:,2].copy().astype(np.int32)\n-    ey = total_boxes[:,3].copy().astype(np.int32)\n+    x = total_boxes[:, 0].copy().astype(np.int32)\n+    y = total_boxes[:, 1].copy().astype(np.int32)\n+    ex = total_boxes[:, 2].copy().astype(np.int32)\n+    ey = total_boxes[:, 3].copy().astype(np.int32)\n \n-    tmp = np.where(ex>w)\n-    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n+    tmp = np.where(ex > w)\n+    edx.flat[tmp] = np.expand_dims(-ex[tmp] + w + tmpw[tmp], 1)\n     ex[tmp] = w\n-    \n-    tmp = np.where(ey>h)\n-    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n+\n+    tmp = np.where(ey > h)\n+    edy.flat[tmp] = np.expand_dims(-ey[tmp] + h + tmph[tmp], 1)\n     ey[tmp] = h\n \n-    tmp = np.where(x<1)\n-    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n+    tmp = np.where(x < 1)\n+    dx.flat[tmp] = np.expand_dims(2 - x[tmp], 1)\n     x[tmp] = 1\n \n-    tmp = np.where(y<1)\n-    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n+    tmp = np.where(y < 1)\n+    dy.flat[tmp] = np.expand_dims(2 - y[tmp], 1)\n     y[tmp] = 1\n-    \n+\n     return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n \n+\n # function [bboxA] = rerec(bboxA)\n def rerec(bboxA):\n     """Convert bboxA to square."""\n-    h = bboxA[:,3]-bboxA[:,1]\n-    w = bboxA[:,2]-bboxA[:,0]\n+    h = bboxA[:, 3] - bboxA[:, 1]\n+    w = bboxA[:, 2] - bboxA[:, 0]\n     l = np.maximum(w, h)\n-    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n-    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n-    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n+    bboxA[:, 0] = bboxA[:, 0] + w * 0.5 - l * 0.5\n+    bboxA[:, 1] = bboxA[:, 1] + h * 0.5 - l * 0.5\n+    bboxA[:, 2:4] = bboxA[:, 0:2] + np.transpose(np.tile(l, (2, 1)))\n     return bboxA\n \n+\n def imresample(img, sz):\n-    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n+    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA)  # @UndefinedVariable\n     return im_data\n \n     # This method is kept for debugging purpose\n@@ -778,4 +791,3 @@ def imresample(img, sz):\n #             for a3 in range(0,3):\n #                 im_data[a1,a2,a3] = img[int(floor(a1*dy)),int(floor(a2*dx)),a3]\n #     return im_data\n-\ndiff --git a/src/align/facenet.py b/src/align/facenet.py\nnew file mode 100644\nindex 0000000..5a603e4\n--- /dev/null\n+++ b/src/align/facenet.py\n@@ -0,0 +1,629 @@\n+"""Functions for building the face recognition network.\n+"""\n+# MIT License\n+#\n+# Copyright (c) 2016 David Sandberg\n+#\n+# Permission is hereby granted, free of charge, to any person obtaining a copy\n+# of this software and associated documentation files (the "Software"), to deal\n+# in the Software without restriction, including without limitation the rights\n+# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n+# copies of the Software, and to permit persons to whom the Software is\n+# furnished to do so, subject to the following conditions:\n+#\n+# The above copyright notice and this permission notice shall be included in all\n+# copies or substantial portions of the Software.\n+#\n+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n+# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n+# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n+# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n+# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n+# SOFTWARE.\n+\n+# pylint: disable=missing-docstring\n+from __future__ import absolute_import\n+from __future__ import division\n+from __future__ import print_function\n+\n+import os\n+from subprocess import Popen, PIPE\n+import tensorflow.compat.v1 as tf\n+import numpy as np\n+# from scipy import misc\n+import imageio as misc  # fake scipy\n+from sklearn.model_selection import KFold\n+from scipy import interpolate\n+from tensorflow.python.training import training\n+import random\n+import re\n+from tensorflow.python.platform import gfile\n+import math\n+from six import iteritems\n+import cv2\n+\n+\n+def triplet_loss(anchor, positive, negative, alpha):\n+    """Calculate the triplet loss according to the FaceNet paper\n+\n+    Args:\n+      anchor: the embeddings for the anchor images.\n+      positive: the embeddings for the positive images.\n+      negative: the embeddings for the negative images.\n+\n+    Returns:\n+      the triplet loss according to the FaceNet paper as a float tensor.\n+    """\n+    with tf.variable_scope(\'triplet_loss\'):\n+        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n+        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n+\n+        basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n+        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n+\n+    return loss\n+\n+\n+def center_loss(features, label, alfa, nrof_classes):\n+    """Center loss based on the paper "A Discriminative Feature Learning Approach for Deep Face Recognition"\n+       (http://ydwen.github.io/papers/WenECCV16.pdf)\n+    """\n+    nrof_features = features.get_shape()[1]\n+    centers = tf.get_variable(\'centers\', [nrof_classes, nrof_features], dtype=tf.float32,\n+                              initializer=tf.constant_initializer(0), trainable=False)\n+    label = tf.reshape(label, [-1])\n+    centers_batch = tf.gather(centers, label)\n+    diff = (1 - alfa) * (centers_batch - features)\n+    centers = tf.scatter_sub(centers, label, diff)\n+    with tf.control_dependencies([centers]):\n+        loss = tf.reduce_mean(tf.square(features - centers_batch))\n+    return loss, centers\n+\n+\n+def get_image_paths_and_labels(dataset):\n+    image_paths_flat = []\n+    labels_flat = []\n+    for i in range(len(dataset)):\n+        image_paths_flat += dataset[i].image_paths\n+        labels_flat += [i] * len(dataset[i].image_paths)\n+    return image_paths_flat, labels_flat\n+\n+\n+def shuffle_examples(image_paths, labels):\n+    shuffle_list = list(zip(image_paths, labels))\n+    random.shuffle(shuffle_list)\n+    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n+    return image_paths_shuff, labels_shuff\n+\n+# def random_rotate_image(image):\n+#     angle = np.random.uniform(low=-10.0, high=10.0)\n+#     return misc.imrotate(image, angle, \'bicubic\')\n+\n+\n+# 1: Random rotate 2: Random crop  4: Random flip  8:  Fixed image standardization  16: Flip\n+RANDOM_ROTATE = 1\n+RANDOM_CROP = 2\n+RANDOM_FLIP = 4\n+FIXED_STANDARDIZATION = 8\n+FLIP = 16\n+\n+\n+def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):\n+    images_and_labels_list = []\n+    for _ in range(nrof_preprocess_threads):\n+        filenames, label, control = input_queue.dequeue()\n+        images = []\n+        for filename in tf.unstack(filenames):\n+            file_contents = tf.read_file(filename)\n+            image = tf.image.decode_image(file_contents, 3)\n+            image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),\n+                            lambda: tf.py_func(random_rotate_image, [\n+                                               image], tf.uint8),\n+                            lambda: tf.identity(image))\n+            image = tf.cond(get_control_flag(control[0], RANDOM_CROP),\n+                            lambda: tf.random_crop(image, image_size + (3,)),\n+                            lambda: tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))\n+            image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),\n+                            lambda: tf.image.random_flip_left_right(image),\n+                            lambda: tf.identity(image))\n+            image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),\n+                            lambda: (tf.cast(image, tf.float32) - 127.5)/128.0,\n+                            lambda: tf.image.per_image_standardization(image))\n+            image = tf.cond(get_control_flag(control[0], FLIP),\n+                            lambda: tf.image.flip_left_right(image),\n+                            lambda: tf.identity(image))\n+            #pylint: disable=no-member\n+            image.set_shape(image_size + (3,))\n+            images.append(image)\n+        images_and_labels_list.append([images, label])\n+\n+    image_batch, label_batch = tf.train.batch_join(\n+        images_and_labels_list, batch_size=batch_size_placeholder,\n+        shapes=[image_size + (3,), ()], enqueue_many=True,\n+        capacity=4 * nrof_preprocess_threads * 100,\n+        allow_smaller_final_batch=True)\n+\n+    return image_batch, label_batch\n+\n+\n+def get_control_flag(control, field):\n+    return tf.equal(tf.mod(tf.floor_div(control, field), 2), 1)\n+\n+\n+def _add_loss_summaries(total_loss):\n+    """Add summaries for losses.\n+\n+    Generates moving average for all losses and associated summaries for\n+    visualizing the performance of the network.\n+\n+    Args:\n+      total_loss: Total loss from loss().\n+    Returns:\n+      loss_averages_op: op for generating moving averages of losses.\n+    """\n+    # Compute the moving average of all individual losses and the total loss.\n+    loss_averages = tf.train.ExponentialMovingAverage(0.9, name=\'avg\')\n+    losses = tf.get_collection(\'losses\')\n+    loss_averages_op = loss_averages.apply(losses + [total_loss])\n+\n+    # Attach a scalar summmary to all individual losses and the total loss; do the\n+    # same for the averaged version of the losses.\n+    for l in losses + [total_loss]:\n+        # Name each loss as \'(raw)\' and name the moving average version of the loss\n+        # as the original loss name.\n+        tf.summary.scalar(l.op.name + \' (raw)\', l)\n+        tf.summary.scalar(l.op.name, loss_averages.average(l))\n+\n+    return loss_averages_op\n+\n+\n+def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n+    # Generate moving averages of all losses and associated summaries.\n+    loss_averages_op = _add_loss_summaries(total_loss)\n+\n+    # Compute gradients.\n+    with tf.control_dependencies([loss_averages_op]):\n+        if optimizer == \'ADAGRAD\':\n+            opt = tf.train.AdagradOptimizer(learning_rate)\n+        elif optimizer == \'ADADELTA\':\n+            opt = tf.train.AdadeltaOptimizer(\n+                learning_rate, rho=0.9, epsilon=1e-6)\n+        elif optimizer == \'ADAM\':\n+            opt = tf.train.AdamOptimizer(\n+                learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n+        elif optimizer == \'RMSPROP\':\n+            opt = tf.train.RMSPropOptimizer(\n+                learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n+        elif optimizer == \'MOM\':\n+            opt = tf.train.MomentumOptimizer(\n+                learning_rate, 0.9, use_nesterov=True)\n+        else:\n+            raise ValueError(\'Invalid optimization algorithm\')\n+\n+        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n+\n+    # Apply gradients.\n+    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n+\n+    # Add histograms for trainable variables.\n+    if log_histograms:\n+        for var in tf.trainable_variables():\n+            tf.summary.histogram(var.op.name, var)\n+\n+    # Add histograms for gradients.\n+    if log_histograms:\n+        for grad, var in grads:\n+            if grad is not None:\n+                tf.summary.histogram(var.op.name + \'/gradients\', grad)\n+\n+    # Track the moving averages of all trainable variables.\n+    variable_averages = tf.train.ExponentialMovingAverage(\n+        moving_average_decay, global_step)\n+    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n+\n+    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n+        train_op = tf.no_op(name=\'train\')\n+\n+    return train_op\n+\n+\n+def prewhiten(x):\n+    mean = np.mean(x)\n+    std = np.std(x)\n+    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n+    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n+    return y\n+\n+\n+def crop(image, random_crop, image_size):\n+    if image.shape[1] > image_size:\n+        sz1 = int(image.shape[1]//2)\n+        sz2 = int(image_size//2)\n+        if random_crop:\n+            diff = sz1-sz2\n+            (h, v) = (np.random.randint(-diff, diff+1),\n+                      np.random.randint(-diff, diff+1))\n+        else:\n+            (h, v) = (0, 0)\n+        image = image[(sz1-sz2+v):(sz1+sz2+v), (sz1-sz2+h):(sz1+sz2+h), :]\n+    return image\n+\n+\n+def flip(image, random_flip):\n+    if random_flip and np.random.choice([True, False]):\n+        image = np.fliplr(image)\n+    return image\n+\n+\n+def to_rgb(img):\n+    w, h = img.shape\n+    ret = np.empty((w, h, 3), dtype=np.uint8)\n+    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n+    return ret\n+\n+\n+def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n+    nrof_samples = len(image_paths)\n+    images = np.zeros((nrof_samples, image_size, image_size, 3))\n+    for i in range(nrof_samples):\n+        img = misc.imread(image_paths[i])\n+        if img.ndim == 2:\n+            img = to_rgb(img)\n+        if do_prewhiten:\n+            img = prewhiten(img)\n+        img = crop(img, do_random_crop, image_size)\n+        img = flip(img, do_random_flip)\n+        img = cv2.resize(img, dsize=(160, 160))\n+        images[i, :, :, :] = img\n+    return images\n+\n+\n+def get_label_batch(label_data, batch_size, batch_index):\n+    nrof_examples = np.size(label_data, 0)\n+    j = batch_index*batch_size % nrof_examples\n+    if j+batch_size <= nrof_examples:\n+        batch = label_data[j:j+batch_size]\n+    else:\n+        x1 = label_data[j:nrof_examples]\n+        x2 = label_data[0:nrof_examples-j]\n+        batch = np.vstack([x1, x2])\n+    batch_int = batch.astype(np.int64)\n+    return batch_int\n+\n+\n+def get_batch(image_data, batch_size, batch_index):\n+    nrof_examples = np.size(image_data, 0)\n+    j = batch_index*batch_size % nrof_examples\n+    if j+batch_size <= nrof_examples:\n+        batch = image_data[j:j+batch_size, :, :, :]\n+    else:\n+        x1 = image_data[j:nrof_examples, :, :, :]\n+        x2 = image_data[0:nrof_examples-j, :, :, :]\n+        batch = np.vstack([x1, x2])\n+    batch_float = batch.astype(np.float32)\n+    return batch_float\n+\n+\n+def get_triplet_batch(triplets, batch_index, batch_size):\n+    ax, px, nx = triplets\n+    a = get_batch(ax, int(batch_size/3), batch_index)\n+    p = get_batch(px, int(batch_size/3), batch_index)\n+    n = get_batch(nx, int(batch_size/3), batch_index)\n+    batch = np.vstack([a, p, n])\n+    return batch\n+\n+\n+def get_learning_rate_from_file(filename, epoch):\n+    with open(filename, \'r\') as f:\n+        for line in f.readlines():\n+            line = line.split(\'#\', 1)[0]\n+            if line:\n+                par = line.strip().split(\':\')\n+                e = int(par[0])\n+                if par[1] == \'-\':\n+                    lr = -1\n+                else:\n+                    lr = float(par[1])\n+                if e <= epoch:\n+                    learning_rate = lr\n+                else:\n+                    return learning_rate\n+\n+\n+class ImageClass():\n+    "Stores the paths to images for a given class"\n+\n+    def __init__(self, name, image_paths):\n+        self.name = name\n+        self.image_paths = image_paths\n+\n+    def __str__(self):\n+        return self.name + \', \' + str(len(self.image_paths)) + \' images\'\n+\n+    def __len__(self):\n+        return len(self.image_paths)\n+\n+\n+def get_dataset(path, has_class_directories=True):\n+    dataset = []\n+    path_exp = os.path.expanduser(path)\n+    classes = [path for path in os.listdir(path_exp)\n+               if os.path.isdir(os.path.join(path_exp, path))]\n+    classes.sort()\n+    nrof_classes = len(classes)\n+    for i in range(nrof_classes):\n+        class_name = classes[i]\n+        facedir = os.path.join(path_exp, class_name)\n+        image_paths = get_image_paths(facedir)\n+        dataset.append(ImageClass(class_name, image_paths))\n+\n+    return dataset\n+\n+\n+def get_image_paths(facedir):\n+    image_paths = []\n+    if os.path.isdir(facedir):\n+        images = os.listdir(facedir)\n+        image_paths = [os.path.join(facedir, img) for img in images]\n+    return image_paths\n+\n+\n+def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\n+    if mode == \'SPLIT_CLASSES\':\n+        nrof_classes = len(dataset)\n+        class_indices = np.arange(nrof_classes)\n+        np.random.shuffle(class_indices)\n+        split = int(round(nrof_classes*(1-split_ratio)))\n+        train_set = [dataset[i] for i in class_indices[0:split]]\n+        test_set = [dataset[i] for i in class_indices[split:-1]]\n+    elif mode == \'SPLIT_IMAGES\':\n+        train_set = []\n+        test_set = []\n+        for cls in dataset:\n+            paths = cls.image_paths\n+            np.random.shuffle(paths)\n+            nrof_images_in_class = len(paths)\n+            split = int(math.floor(nrof_images_in_class*(1-split_ratio)))\n+            if split == nrof_images_in_class:\n+                split = nrof_images_in_class-1\n+            if split >= min_nrof_images_per_class and nrof_images_in_class-split >= 1:\n+                train_set.append(ImageClass(cls.name, paths[:split]))\n+                test_set.append(ImageClass(cls.name, paths[split:]))\n+    else:\n+        raise ValueError(\'Invalid train/test split mode "%s"\' % mode)\n+    return train_set, test_set\n+\n+\n+def load_model(model, input_map=None):\n+    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n+    #  or if it is a protobuf file with a frozen graph\n+    model_exp = os.path.expanduser(model)\n+    if (os.path.isfile(model_exp)):\n+        print(\'Model filename: %s\' % model_exp)\n+        with gfile.FastGFile(model_exp, \'rb\') as f:\n+            graph_def = tf.GraphDef()\n+            graph_def.ParseFromString(f.read())\n+            tf.import_graph_def(graph_def, input_map=input_map, name=\'\')\n+    else:\n+        print(\'Model directory: %s\' % model_exp)\n+        meta_file, ckpt_file = get_model_filenames(model_exp)\n+\n+        print(\'Metagraph file: %s\' % meta_file)\n+        print(\'Checkpoint file: %s\' % ckpt_file)\n+\n+        saver = tf.train.import_meta_graph(os.path.join(\n+            model_exp, meta_file), input_map=input_map)\n+        saver.restore(tf.get_default_session(),\n+                      os.path.join(model_exp, ckpt_file))\n+\n+\n+def get_model_filenames(model_dir):\n+    files = os.listdir(model_dir)\n+    meta_files = [s for s in files if s.endswith(\'.meta\')]\n+    if len(meta_files) == 0:\n+        raise ValueError(\n+            \'No meta file found in the model directory (%s)\' % model_dir)\n+    elif len(meta_files) > 1:\n+        raise ValueError(\n+            \'There should not be more than one meta file in the model directory (%s)\' % model_dir)\n+    meta_file = meta_files[0]\n+    ckpt = tf.train.get_checkpoint_state(model_dir)\n+    if ckpt and ckpt.model_checkpoint_path:\n+        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n+        return meta_file, ckpt_file\n+\n+    meta_files = [s for s in files if \'.ckpt\' in s]\n+    max_step = -1\n+    for f in files:\n+        step_str = re.match(r\'(^model-[\\w\\- ]+.ckpt-(\\d+))\', f)\n+        if step_str is not None and len(step_str.groups()) >= 2:\n+            step = int(step_str.groups()[1])\n+            if step > max_step:\n+                max_step = step\n+                ckpt_file = step_str.groups()[0]\n+    return meta_file, ckpt_file\n+\n+\n+def distance(embeddings1, embeddings2, distance_metric=0):\n+    if distance_metric == 0:\n+        # Euclidian distance\n+        diff = np.subtract(embeddings1, embeddings2)\n+        dist = np.sum(np.square(diff), 1)\n+    elif distance_metric == 1:\n+        # Distance based on cosine similarity\n+        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n+        norm = np.linalg.norm(embeddings1, axis=1) * \\\n+            np.linalg.norm(embeddings2, axis=1)\n+        similarity = dot / norm\n+        dist = np.arccos(similarity) / math.pi\n+    else:\n+        raise \'Undefined distance metric %d\' % distance_metric\n+\n+    return dist\n+\n+\n+def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n+    assert(embeddings1.shape[0] == embeddings2.shape[0])\n+    assert(embeddings1.shape[1] == embeddings2.shape[1])\n+    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n+    nrof_thresholds = len(thresholds)\n+    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n+\n+    tprs = np.zeros((nrof_folds, nrof_thresholds))\n+    fprs = np.zeros((nrof_folds, nrof_thresholds))\n+    accuracy = np.zeros((nrof_folds))\n+\n+    indices = np.arange(nrof_pairs)\n+\n+    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n+        if subtract_mean:\n+            mean = np.mean(np.concatenate(\n+                [embeddings1[train_set], embeddings2[train_set]]), axis=0)\n+        else:\n+            mean = 0.0\n+        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n+\n+        # Find the best threshold for the fold\n+        acc_train = np.zeros((nrof_thresholds))\n+        for threshold_idx, threshold in enumerate(thresholds):\n+            _, _, acc_train[threshold_idx] = calculate_accuracy(\n+                threshold, dist[train_set], actual_issame[train_set])\n+        best_threshold_index = np.argmax(acc_train)\n+        for threshold_idx, threshold in enumerate(thresholds):\n+            tprs[fold_idx, threshold_idx], fprs[fold_idx, threshold_idx], _ = calculate_accuracy(\n+                threshold, dist[test_set], actual_issame[test_set])\n+        _, _, accuracy[fold_idx] = calculate_accuracy(\n+            thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n+\n+        tpr = np.mean(tprs, 0)\n+        fpr = np.mean(fprs, 0)\n+    return tpr, fpr, accuracy\n+\n+\n+def calculate_accuracy(threshold, dist, actual_issame):\n+    predict_issame = np.less(dist, threshold)\n+    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n+    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n+    tn = np.sum(np.logical_and(np.logical_not(\n+        predict_issame), np.logical_not(actual_issame)))\n+    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n+\n+    tpr = 0 if (tp+fn == 0) else float(tp) / float(tp+fn)\n+    fpr = 0 if (fp+tn == 0) else float(fp) / float(fp+tn)\n+    acc = float(tp+tn)/dist.size\n+    return tpr, fpr, acc\n+\n+\n+def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n+    assert(embeddings1.shape[0] == embeddings2.shape[0])\n+    assert(embeddings1.shape[1] == embeddings2.shape[1])\n+    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n+    nrof_thresholds = len(thresholds)\n+    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n+\n+    val = np.zeros(nrof_folds)\n+    far = np.zeros(nrof_folds)\n+\n+    indices = np.arange(nrof_pairs)\n+\n+    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n+        if subtract_mean:\n+            mean = np.mean(np.concatenate(\n+                [embeddings1[train_set], embeddings2[train_set]]), axis=0)\n+        else:\n+            mean = 0.0\n+        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n+\n+        # Find the threshold that gives FAR = far_target\n+        far_train = np.zeros(nrof_thresholds)\n+        for threshold_idx, threshold in enumerate(thresholds):\n+            _, far_train[threshold_idx] = calculate_val_far(\n+                threshold, dist[train_set], actual_issame[train_set])\n+        if np.max(far_train) >= far_target:\n+            f = interpolate.interp1d(far_train, thresholds, kind=\'slinear\')\n+            threshold = f(far_target)\n+        else:\n+            threshold = 0.0\n+\n+        val[fold_idx], far[fold_idx] = calculate_val_far(\n+            threshold, dist[test_set], actual_issame[test_set])\n+\n+    val_mean = np.mean(val)\n+    far_mean = np.mean(far)\n+    val_std = np.std(val)\n+    return val_mean, val_std, far_mean\n+\n+\n+def calculate_val_far(threshold, dist, actual_issame):\n+    predict_issame = np.less(dist, threshold)\n+    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n+    false_accept = np.sum(np.logical_and(\n+        predict_issame, np.logical_not(actual_issame)))\n+    n_same = np.sum(actual_issame)\n+    n_diff = np.sum(np.logical_not(actual_issame))\n+    val = float(true_accept) / float(n_same)\n+    far = float(false_accept) / float(n_diff)\n+    return val, far\n+\n+\n+def store_revision_info(src_path, output_dir, arg_string):\n+    try:\n+        # Get git hash\n+        cmd = [\'git\', \'rev-parse\', \'HEAD\']\n+        gitproc = Popen(cmd, stdout=PIPE, cwd=src_path)\n+        (stdout, _) = gitproc.communicate()\n+        git_hash = stdout.strip()\n+    except OSError as e:\n+        git_hash = \' \'.join(cmd) + \': \' + e.strerror\n+\n+    try:\n+        # Get local changes\n+        cmd = [\'git\', \'diff\', \'HEAD\']\n+        gitproc = Popen(cmd, stdout=PIPE, cwd=src_path)\n+        (stdout, _) = gitproc.communicate()\n+        git_diff = stdout.strip()\n+    except OSError as e:\n+        git_diff = \' \'.join(cmd) + \': \' + e.strerror\n+\n+    # Store a text file in the log directory\n+    rev_info_filename = os.path.join(output_dir, \'revision_info.txt\')\n+    with open(rev_info_filename, "w") as text_file:\n+        text_file.write(\'arguments: %s\\n--------------------\\n\' % arg_string)\n+        text_file.write(\'tensorflow version: %s\\n--------------------\\n\' %\n+                        tf.__version__)  # @UndefinedVariable\n+        text_file.write(\'git hash: %s\\n--------------------\\n\' % git_hash)\n+        text_file.write(\'%s\' % git_diff)\n+\n+\n+def list_variables(filename):\n+    reader = training.NewCheckpointReader(filename)\n+    variable_map = reader.get_variable_to_shape_map()\n+    names = sorted(variable_map.keys())\n+    return names\n+\n+\n+def put_images_on_grid(images, shape=(16, 8)):\n+    nrof_images = images.shape[0]\n+    img_size = images.shape[1]\n+    bw = 3\n+    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]\n+                   * (img_size+bw)+bw, 3), np.float32)\n+    for i in range(shape[1]):\n+        x_start = i*(img_size+bw)+bw\n+        for j in range(shape[0]):\n+            img_index = i*shape[0]+j\n+            if img_index >= nrof_images:\n+                break\n+            y_start = j*(img_size+bw)+bw\n+            img[x_start:x_start+img_size, y_start:y_start +\n+                img_size, :] = images[img_index, :, :, :]\n+        if img_index >= nrof_images:\n+            break\n+    return img\n+\n+\n+def write_arguments_to_file(args, filename):\n+    with open(filename, \'w\') as f:\n+        for key, value in iteritems(vars(args)):\n+            f.write(\'%s: %s\\n\' % (key, str(value)))\ndiff --git a/src/classifier.py b/src/classifier.py\nindex 9ac7f35..d98551e 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -54,6 +54,7 @@ def main(args):\n                     dataset = test_set\n             else:\n                 dataset = facenet.get_dataset(args.data_dir)\n+            print(\'data set \', type(dataset))\n \n             # Check that there are at least one training image per class\n             for cls in dataset:\ndiff --git a/tutorial.txt b/tutorial.txt\nindex da2b99e..b64f377 100644\n--- a/tutorial.txt\n+++ b/tutorial.txt\n@@ -1,6 +1,7 @@\n train with own dataset :\n /usr/bin/python3 src/classifier.py TRAIN /home/thai/Data1/VN-celeb/ /home/thai/Data1/20180408-102900/20180408-102900.pb /home/thai/Data2/facenet/src/models/lwf_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset\n /usr/bin/python3 src/classifier.py TRAIN /home/it/Data/dataset/VN-celeb/ /home/it/Data/models/20180408-102900/20180408-102900.pb /home/it/Data/thaiphData/facenet/src/models/lwf_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset\n+/usr/bin/python3 src/classifier.py TRAIN /home/thai/Data2/face-recognition-system/dataset/ /home/thai/Data1/20180408-102900/20180408-102900.pb /home/thai/Data2/facenet/src/models/lwf_classifier.pkl --batch_size 1000 --min_nrof_images_per_class 40 --nrof_train_images_per_class 35 --use_split_dataset\n \n test accuracy :\n /usr/bin/python3 src/classifier.py CLASSIFY /home/thai/Data1/VN-celeb/ /home/thai/Data1/20180408-102900/20180408-102900.pb /home/thai/Data2/facenet/src/models/lwf_classifier.pkl --batch_size 1000\n@@ -8,4 +9,10 @@ test accuracy :\n \n train triplet loss :\n /usr/bin/python3 src/train_tripletloss.py --logs_base_dir ~/logs/facenet/ --models_base_dir ~/models/facenet/ --data_dir /home/thai/Data1/VN-celeb/ --image_size 160 --model_def models.inception_resnet_v1 --optimizer RMSPROP --learning_rate 0.01 --weight_decay 1e-4 --max_nrof_epochs 500\n-/usr/bin/python3 src/train_tripletloss.py --logs_base_dir ~/logs/facenet/ --models_base_dir ~/models/facenet/ --data_dir /home/it/Data/dataset/VN-celeb/ --image_size 160 --model_def models.inception_resnet_v1 --optimizer RMSPROP --learning_rate 0.01 --weight_decay 1e-4 --max_nrof_epochs 500\n\\ No newline at end of file\n+/usr/bin/python3 src/train_tripletloss.py --logs_base_dir ~/logs/facenet/ --models_base_dir ~/models/facenet/ --data_dir /home/it/Data/dataset/VN-celeb/ --image_size 160 --model_def models.inception_resnet_v1 --optimizer RMSPROP --learning_rate 0.01 --weight_decay 1e-4 --max_nrof_epochs 500\n+\n+/usr/bin/python3 src/align/align_dataset_mtcnn.py \\\n+dataset/datatrain \\\n+datasets/dataalign \\\n+--image_size 182 \\\n+--margin 44\n\\ No newline at end of file'